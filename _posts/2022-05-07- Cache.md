# 高速缓冲存储器(Cache)

## 程序访问局部性原理:

### 时间局部性:

指最近的未来要用到的信息,很可能是现在正在使用的信息,因为程序中存在循环.(循环的程序能体现时间局部性)

### 空间局部性:

指最近的未来要用到的信息,很可能与正在使用的信息在存储空间上临近,因为指令通常是顺序存放、顺序执行的.

### Cache

高速缓冲技术就是利用了局部性原理,把程序中正在使用的部分数据存放在一个高速的容量小的Cache中,使CPU的绝大部分访存操作针对Cache进行,提高程序执行速度.

### 程序访问局部性举例

```c++
//程序A (按a[0][0],a[0][1]……访问)
int sumArrayRows(int a[M][N]) {
	int i, j, sum = 0;
  for (i = 0; i < M; ++i) 
		for (int j = 0; j < N; ++j) 
      sum += a[i][j];
}
//程序B (按a[0][0],a[1][0]……访问)
int sumArrayRows(int a[M][N]) {
	int i, j, sum = 0;
  for (i = 0; i < N; ++i) 
		for (int j = 0; j < M; ++j) 
      sum += a[j][i];
}
```

#### 对于数组a:

​		两程序的空间局部性相差较大,因为程序A是按数据存放顺序进行访问,空间局部性好.而程序B访问顺序与数据存放顺序不一致,如果Cache容量小于或等于数组a中每一层数组的容量,那每访问一次数组,都要将该数组元素所在的主存块装入Cache,因此没有空间局部性.

因为两程序数组元素都被访问一次,所以两程序的时间局部性差.

#### 对于for循环:

两程序的局部性相同,因为循环体内指令按序连续存放,所以空间局部性好,循环体被重复执行了很多次,时间局部性也好.

## Cache原理

Cache由SRAM构成,所以读写速度很快.为便于交换信息,Cache和主存被分为若干大小相等的块,每个块也被称为一个Cache行,由若干字节组成.块的长度被称为块长.因为Cache容量远小于主存容量,所以块的数量也远小于主存.它只保存主存中常使用的若干块的副本,所以Cache会按照某种策略,预测CPU未来一段时间内要访存的数据,并将其所在的块装入Cache.

CPU发出读请求,如果访存地址在Cache中命中,那就将此地址转换为Cache地址,直接对Cache进行读,不对主存进行操作.如果访存的地址在Cache中未命中,则需要访问主存,并将该地址所在的块装入Cache.如果Cache已满,则根据某种替换算法,替换Cache中的内容.

CPU与Cache数据交换的基本单位是**字**,而Cache与主存之间数据交换的基本单位是**块**.

## Cache与主存的映射关系:

Cache块中的信息是主存某块的副本,地址映射是把主存地址空间映射到Cache地址空间,说人话就是把主存中的信息按照某种规则装入Cache.

因为Cache容量有限,储存中只有少数块的信息可以放在Cache中,所以Cache要为每一块加一个标记,表明其是主存哪一块的副本.标记内容相当于主存中块的编号,而且为了说明Cache中的某块内容是否有效,Cache每块会有一位有效位.

### 地址映射方法:

#### 直接映射:

主存中每一块只能装入Cache中的唯一位置,若此时产生了冲突,直接替换块中的内容,无需替换算法.

直接映射方法简单,易于实现,但是不够灵活,冲突率很高,容易使Cache中很多地址空着但无法利用,空间利用率低.

​			Cache行号 = 主存块号 mod Cache总行数

直接映射的地址结构为:

​			|    标记(t位)    |    Cache行号(c位)    |    块内地址(b位)    |

标记位辨别Cache行号相同的主存块.

一个Cache行由有效位、标记和数据构成

#### 全相联映射

主存中的每一块都可以装入Cache中的任何位置,每一行的标记指出该行取自主存的哪一块,所以CPU访存时,需要与所有Cache行进行比较.全相联映射优点是比较灵活,Cache访存冲突率低,空间利用率高,且命中率高;缺点是标记的比较速度较慢,实现成本高,通常采用昂贵的按内容寻址的相联存储区进行地址映射.

全相联映射地址结构:

​			|			标记(主存块号)			|	块内地址	|

#### 组相联映射

将Cache分为Q个大小相等的组,每个主存块可以装入固定组的任意一行,即组间采用直接映射,组内采用全相联映射.当Q=1时变为全相联映射,Q为Cache行数时,为直接映射.每组R行,称之为R路组相联

组相联映射的关系可以定义为:

​			Cache组号 = 主存块号 mod Cache组数

组相联地址结构为:

​			|	标记	|	组号	|	块内地址	|

CPU访存过程: 根据访存地址中间的组号,找到对应的组,在对应的组中,对每个行的标记与主存标记进行比对,如果相等且有效位为1,则Cache命中.若不命中,则从主存中将地址所在的块送入Cache对应组的任意空闲行,将有效位置1,并设置标记,同时将内容送至CPU.

## Cache中主存块替换算法

采用全相联或组相联映射方法时,主存向Cache送入一块新块,当Cache或Cache组空间被占满时,就需要使用替换算法,替换Cache行,而采用直接映射,发生冲突时,直接替换,无需替换算法.

### 常用替换算法:

**随机(RAND)算法:**随机确定要替换的Cache块,实现简单,但为根据程序的局部性原理.

**先进先出(FIFO)算法:**选择最早调入的行进行替换,实现简单,但也未根据程序访问的局部性原理,因为最早访问的可能是最近常要用的.

**最近最少使用(LRU)算法:**根据程序访问的局部性原理,选择最近常期未访问过的Cache行进行替换,平均命中率比FIFO高,是堆栈类算法.

LRU算法对每个Cache块设置一个计数器,用计数器来记录主存块的使用情况.计数器块数与Cache组大小相关,2路有一位LRU位,4路有2位LRU位.

计数器变化规则(假定四路组相联映射):

1. 命中时,所命中行的计数器清零,比其低的计数器+1,其余不变
2. 未命中且还有空闲行时,新装入的行计数器置0,其余行计数器+1
3. 未命中且无空闲行时,计数值为3的信息块淘汰,新装入的行计数器置0,其余+1

## Cache写策略

### 写命中:

#### 全写法(写直通法,write- through):

当CPU对Cache写命中时,将数据同时写入Cache和主存,当Cache某块需要替换时,直接覆盖即可.

这种方法操作简单,能随时保持主存数据的正确性,但是会增加访存次数,降低Cache效率

#### 回写法(写会法,write- back):

当CPU对Cache写命中时,只将数据写入Cache,而不立即写入主存,只有该块被替换时,才将Cache中内容写回主存.

这种方法减少了访存次数,当存在不一致的隐患,为减少写回主存的开销,每个Cache行设置一个脏位(修改位),脏位为1,说明Cache中内容被修改过,替换时需要写为主存,脏位为0,则直接替换,无需写入主存.

### 写不命中

#### 写分配法:

加载主存到Cache块中,更新这个Cache块,它试图利用程序的空间局部性,但是每次不命中都需要从主存中读取一块

#### 非写分配法

直接写入主存,不进行调块.

写分配法通常与回写法配合使用,非写分配法法通常与全写法配合使用..

## 多级Cache结构

### 指令Cache和数据Cache分离的Cache结构

统一的Cache结构设计和实现相对简单,当由于执行部件存取数据时,指令预取部件要从同一Cache读指令,会引发冲突,采用指令和数据分离的Cache可以解决这一问题,且分离的指令和数据可以充分采用指令和数据的不同局部性优化性能.

### 多级Cache

现代计算机通常设立多级Cache,假设3级Cache,按离CPU的远近,可命名为L1Cache, L2Cache, L3Cache,离CPU越远,访问速度越慢,容量越大.指令Cache与数据Cache分离一般在L1 Cache,此时通常为写分配法与回写法合用.